{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 설정 & 경로"
      ],
      "metadata": {
        "id": "PX9ueAEoARKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocVQrL4gL7uT",
        "outputId": "598074fa-1c3e-49e6-bde9-17dad236c9ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JhIOiNyX4VO0"
      },
      "outputs": [],
      "source": [
        "DATA_PATH_TEMPLATE = \"/content/drive/MyDrive/Colab Notebooks/mHealth_subject{sid}.log\"\n",
        "\n",
        "SAMPLE_RATE_HZ = 50\n",
        "WIN = 64\n",
        "STRIDE = 64\n",
        "MAJ_THRESH = 0.80\n",
        "\n",
        "N_CLASSES = 12\n",
        "IN_CHANNELS = 23\n",
        "\n",
        "CONV_FILTERS = 8\n",
        "KERNEL_SIZE = 3\n",
        "POOL_SIZE = 2\n",
        "HIDDEN_UNITS = 16\n",
        "\n",
        "EPOCHS = 2\n",
        "BATCH_SIZE = 16\n",
        "LR = 0.01\n",
        "LABEL_SMOOTHING = 0.05\n",
        "\n",
        "# CV folds (subject-based)\n",
        "FOLDS = [(1,2), (3,4), (5,6), (7,8), (9,10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로딩 및 통합 테이블 구성"
      ],
      "metadata": {
        "id": "PqidLeJpAVbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Cell 2: Pure-Python Data Loading & \"Table\" builder ====\n",
        "def read_subject_file(path, sid):\n",
        "    rows = []\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                s = line.strip()\n",
        "                if not s:\n",
        "                    continue\n",
        "                parts = s.split()\n",
        "                if len(parts) < 24:\n",
        "                    continue\n",
        "                feats = []\n",
        "                ok = True\n",
        "                for i in range(23):\n",
        "                    try:\n",
        "                        feats.append(float(parts[i]))\n",
        "                    except:\n",
        "                        ok = False\n",
        "                        break\n",
        "                if not ok:\n",
        "                    continue\n",
        "                try:\n",
        "                    lbl = int(float(parts[23]))\n",
        "                except:\n",
        "                    continue\n",
        "                rows.append((feats, lbl, sid))\n",
        "    except FileNotFoundError:\n",
        "        print(f\"[WARN] File not found for subject {sid}: {path}\")\n",
        "    return rows\n",
        "\n",
        "def load_all_subjects(path_template, sids=range(1,11)):\n",
        "    table = []\n",
        "    for sid in sids:\n",
        "        path = path_template.format(sid=sid)\n",
        "        rows = read_subject_file(path, sid)\n",
        "        for feats, lbl, sub in rows:\n",
        "            table.append({'features': feats, 'label': lbl, 'subject': sub})\n",
        "    print(f\"[INFO] Loaded {len(table)} raw rows from {len(list(sids))} subjects.\")\n",
        "    return table\n",
        "\n",
        "def peek_table(table, n=3):\n",
        "    for i, r in enumerate(table[:n]):\n",
        "        print(i, \"subject=\", r['subject'], \"label=\", r['label'], \"x[:5]=\", r['features'][:5])\n",
        "\n",
        "table = load_all_subjects(DATA_PATH_TEMPLATE, sids=range(1,11))\n",
        "peek_table(table, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OzWb6oFAR19",
        "outputId": "f5c0806e-a26f-4589-f9f2-b1737f7dd6ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded 1215745 raw rows from 10 subjects.\n",
            "0 subject= 1 label= 0 x[:5]= [-9.8184, 0.009971, 0.29563, 0.0041863, 0.0041863]\n",
            "1 subject= 1 label= 0 x[:5]= [-9.8489, 0.52404, 0.37348, 0.0041863, 0.016745]\n",
            "2 subject= 1 label= 0 x[:5]= [-9.6602, 0.18185, 0.43742, 0.016745, 0.037677]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label==0 제거 + 윈도우링(다수라벨 규칙) + 표준화 옵션"
      ],
      "metadata": {
        "id": "HVN5NgCnAYSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Cell 3: Filtering label==0, windowing, and (optional) normalization ====\n",
        "def make_windows(examples, win=100, stride=50, drop_label0=True, maj_thresh=0.80):\n",
        "    by_subj = {}\n",
        "    for r in examples:\n",
        "        by_subj.setdefault(r['subject'], []).append(r)\n",
        "\n",
        "    Xw, Yw = [], []\n",
        "    for sid, seq in by_subj.items():\n",
        "        L = len(seq)\n",
        "        i = 0\n",
        "        while i + win <= L:\n",
        "            chunk = seq[i:i+win]\n",
        "            labels = [r['label'] for r in chunk]\n",
        "            counts = {}\n",
        "            for l in labels:\n",
        "                counts[l] = counts.get(l, 0) + 1\n",
        "            maj = max(counts.keys(), key=lambda k: counts[k])\n",
        "            ratio = counts[maj] / float(win)\n",
        "\n",
        "            if drop_label0 and maj == 0:\n",
        "                i += stride\n",
        "                continue\n",
        "            if ratio < maj_thresh:\n",
        "                i += stride\n",
        "                continue\n",
        "\n",
        "            win_feats = []\n",
        "            for r in chunk:\n",
        "                win_feats.append(r['features'])\n",
        "\n",
        "            if maj == 0:\n",
        "                i += stride\n",
        "                continue\n",
        "            y = maj - 1\n",
        "\n",
        "            Xw.append(win_feats)\n",
        "            Yw.append(y)\n",
        "            i += stride\n",
        "\n",
        "    return Xw, Yw\n",
        "\n",
        "def standardize_per_channel(train_X, valid_or_test_X):\n",
        "    C = IN_CHANNELS\n",
        "    sums  = [0.0]*C\n",
        "    sums2 = [0.0]*C\n",
        "    counts = [0]*C\n",
        "\n",
        "    for w in train_X:\n",
        "        for t in w:\n",
        "            for c in range(C):\n",
        "                v = t[c]\n",
        "                sums[c]  += v\n",
        "                sums2[c] += v*v\n",
        "                counts[c] += 1\n",
        "\n",
        "    means = [ (sums[c]/counts[c] if counts[c]>0 else 0.0) for c in range(C) ]\n",
        "    stds  = []\n",
        "    for c in range(C):\n",
        "        if counts[c] == 0:\n",
        "            stds.append(1.0)\n",
        "        else:\n",
        "            mean = means[c]\n",
        "            var  = (sums2[c]/counts[c]) - (mean*mean)\n",
        "            stds.append( (var**0.5) if var>1e-12 else 1.0 )\n",
        "\n",
        "    def apply(X):\n",
        "        X2 = []\n",
        "        for w in X:\n",
        "            w2 = []\n",
        "            for t in w:\n",
        "                t2 = [(t[c]-means[c])/stds[c] for c in range(C)]\n",
        "                w2.append(t2)\n",
        "            X2.append(w2)\n",
        "        return X2\n",
        "\n",
        "    return apply(train_X), apply(valid_or_test_X)\n",
        "\n",
        "print(\"[INFO] Windowing on full table (will be done per fold later after split).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTstN3UoAY_X",
        "outputId": "0d9eeb51-6944-4f36-82c1-84a13d283419"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Windowing on full table (will be done per fold later after split).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 분할 유틸: 주체 기반 CV 스플릿"
      ],
      "metadata": {
        "id": "FY2NC7unAYfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Cell 4: Subject-wise CV Split utilities ====\n",
        "def split_by_subject(table, test_subjects):\n",
        "    train = [r for r in table if r['subject'] not in test_subjects]\n",
        "    test  = [r for r in table if r['subject'] in test_subjects]\n",
        "    return train, test\n",
        "\n",
        "def build_fold_data(table, test_pair, win=WIN, stride=STRIDE, maj_thresh=MAJ_THRESH):\n",
        "    train_raw, test_raw = split_by_subject(table, test_pair)\n",
        "    Xtr, Ytr = make_windows(train_raw, win=win, stride=stride, drop_label0=True, maj_thresh=maj_thresh)\n",
        "    Xte, Yte = make_windows(test_raw,  win=win, stride=stride, drop_label0=True, maj_thresh=maj_thresh)\n",
        "    Xtr, Xte = standardize_per_channel(Xtr, Xte)\n",
        "    return Xtr, Ytr, Xte, Yte\n"
      ],
      "metadata": {
        "id": "MX7AWrahAZaN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순수 파이썬 1D-CNN 레이어\n",
        "- Conv/ReLU/MaxPool/Flatten/Dense/Softmax"
      ],
      "metadata": {
        "id": "3ixJ6NZxAYh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Cell 5: Pure-Python 1D-CNN implementation (forward/backward) ====\n",
        "import math\n",
        "import random\n",
        "\n",
        "def zeros(shape):\n",
        "    if len(shape) == 1:\n",
        "        return [0.0]*shape[0]\n",
        "    return [zeros(shape[1:]) for _ in range(shape[0])]\n",
        "\n",
        "def randn(shape, scale=0.01):\n",
        "    import random, math\n",
        "    def g():\n",
        "        u1 = max(1e-12, random.random())\n",
        "        u2 = random.random()\n",
        "        return math.sqrt(-2.0*math.log(u1))*math.cos(2*math.pi*u2)\n",
        "    if len(shape) == 1:\n",
        "        return [g()*scale for _ in range(shape[0])]\n",
        "    return [randn(shape[1:], scale) for _ in range(shape[0])]\n",
        "\n",
        "class Conv1D:\n",
        "    def __init__(self, in_ch, out_ch, ksize):\n",
        "        self.in_ch = in_ch\n",
        "        self.out_ch = out_ch\n",
        "        self.ksize = ksize\n",
        "        self.W = randn((out_ch, in_ch, ksize), scale=0.05)\n",
        "        self.b = randn((out_ch,), scale=0.0)\n",
        "        self.gW = zeros((out_ch, in_ch, ksize))\n",
        "        self.gb = zeros((out_ch,))\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):  # x: [T, C]\n",
        "        T = len(x)\n",
        "        k = self.ksize\n",
        "        outT = T - k + 1\n",
        "        y = [[0.0]*self.out_ch for _ in range(outT)]\n",
        "        for t in range(outT):\n",
        "            for oc in range(self.out_ch):\n",
        "                s = self.b[oc]\n",
        "                for ic in range(self.in_ch):\n",
        "                    for kk in range(k):\n",
        "                        s += self.W[oc][ic][kk] * x[t+kk][ic]\n",
        "                y[t][oc] = s\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        return y\n",
        "\n",
        "    def backward(self, dy, lr):\n",
        "        x = self.x\n",
        "        T = len(x)\n",
        "        k = self.ksize\n",
        "        outT = T - k + 1\n",
        "        for oc in range(self.out_ch):\n",
        "            self.gb[oc] = 0.0\n",
        "            for ic in range(self.in_ch):\n",
        "                for kk in range(k):\n",
        "                    self.gW[oc][ic][kk] = 0.0\n",
        "        dx = [[0.0]*self.in_ch for _ in range(T)]\n",
        "        for t in range(outT):\n",
        "            for oc in range(self.out_ch):\n",
        "                g = dy[t][oc]\n",
        "                self.gb[oc] += g\n",
        "                for ic in range(self.in_ch):\n",
        "                    for kk in range(k):\n",
        "                        self.gW[oc][ic][kk] += g * self.x[t+kk][ic]\n",
        "                        dx[t+kk][ic] += g * self.W[oc][ic][kk]\n",
        "        for oc in range(self.out_ch):\n",
        "            self.b[oc] -= lr * self.gb[oc]\n",
        "            for ic in range(self.in_ch):\n",
        "                for kk in range(k):\n",
        "                    self.W[oc][ic][kk] -= lr * self.gW[oc][ic][kk]\n",
        "        return dx\n",
        "\n",
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "    def forward(self, x):  # x: [T, C]\n",
        "        self.mask = [[1.0 if v>0 else 0.0 for v in row] for row in x]\n",
        "        return [[v if v>0 else 0.0 for v in row] for row in x]\n",
        "    def backward(self, dy, lr):\n",
        "        return [[dy[t][c]*self.mask[t][c] for c in range(len(dy[0]))] for t in range(len(dy))]\n",
        "\n",
        "class MaxPool1D:\n",
        "    def __init__(self, pool):\n",
        "        self.pool = pool\n",
        "        self.idx = None\n",
        "    def forward(self, x):  # x: [T, C]\n",
        "        T = len(x)\n",
        "        C = len(x[0])\n",
        "        p = self.pool\n",
        "        outT = T // p\n",
        "        y = [[0.0]*C for _ in range(outT)]\n",
        "        self.idx = [[0]*C for _ in range(outT)]\n",
        "        self.x = x\n",
        "        for t in range(outT):\n",
        "            for c in range(C):\n",
        "                best = -1e18\n",
        "                bi = 0\n",
        "                for i in range(p):\n",
        "                    v = x[t*p+i][c]\n",
        "                    if v > best:\n",
        "                        best = v\n",
        "                        bi = i\n",
        "                y[t][c] = best\n",
        "                self.idx[t][c] = bi\n",
        "        self.y = y\n",
        "        return y\n",
        "    def backward(self, dy, lr):\n",
        "        T = len(self.x)\n",
        "        C = len(self.x[0])\n",
        "        p = self.pool\n",
        "        outT = len(dy)\n",
        "        dx = [[0.0]*C for _ in range(T)]\n",
        "        for t in range(outT):\n",
        "            for c in range(C):\n",
        "                bi = self.idx[t][c]\n",
        "                dx[t*p+bi][c] += dy[t][c]\n",
        "        return dx\n",
        "\n",
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.shape = None\n",
        "    def forward(self, x): # x: [T, C]\n",
        "        self.shape = (len(x), len(x[0]))\n",
        "        out = []\n",
        "        for t in x:\n",
        "            for v in t:\n",
        "                out.append(v)\n",
        "        return out  # [T*C]\n",
        "    def backward(self, dy, lr):\n",
        "        T, C = self.shape\n",
        "        x = []\n",
        "        idx = 0\n",
        "        for _ in range(T):\n",
        "            row = []\n",
        "            for _ in range(C):\n",
        "                row.append(dy[idx]); idx += 1\n",
        "            x.append(row)\n",
        "        return x\n",
        "\n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        self.W = randn((out_dim, in_dim), scale=0.05)\n",
        "        self.b = randn((out_dim,), scale=0.0)\n",
        "        self.gW = zeros((out_dim, in_dim))\n",
        "        self.gb = zeros((out_dim,))\n",
        "        self.x = None\n",
        "    def forward(self, x):  # x: [D]\n",
        "        self.x = x\n",
        "        y = [self.b[o] + sum(self.W[o][i]*x[i] for i in range(len(x))) for o in range(len(self.W))]\n",
        "        return y  # logits\n",
        "    def backward(self, dlogits, lr):\n",
        "        D_out = len(self.W)\n",
        "        D_in  = len(self.W[0])\n",
        "        dx = [0.0]*D_in\n",
        "        for o in range(D_out):\n",
        "            g = dlogits[o]\n",
        "            self.gb[o] += g\n",
        "            for i in range(D_in):\n",
        "                self.gW[o][i] += g * self.x[i]\n",
        "                dx[i] += g * self.W[o][i]\n",
        "        for o in range(D_out):\n",
        "            self.b[o] -= lr * self.gb[o]\n",
        "            self.gb[o] = 0.0\n",
        "            for i in range(D_in):\n",
        "                self.W[o][i] -= lr * self.gW[o][i]\n",
        "                self.gW[o][i] = 0.0\n",
        "        return dx\n",
        "\n",
        "def softmax(logits):\n",
        "    m = max(logits)\n",
        "    exps = [math.exp(v - m) for v in logits]\n",
        "    s = sum(exps)\n",
        "    return [e/s for e in exps]\n",
        "\n",
        "def cross_entropy_with_label_smoothing(probs, y, num_classes, eps=0.0):\n",
        "    K = num_classes\n",
        "    t = [eps/(K-1)]*K\n",
        "    t[y] = 1.0 - eps\n",
        "    loss = 0.0\n",
        "    for k in range(K):\n",
        "        loss -= t[k] * (math.log(max(1e-12, probs[k])))\n",
        "    dlogits = [probs[k] - t[k] for k in range(K)]\n",
        "    return loss, dlogits\n"
      ],
      "metadata": {
        "id": "VKFUzYzkAZre"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 조립 & 트레이너"
      ],
      "metadata": {
        "id": "qztBF-dvAYmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Cell 6: Build model (Conv->ReLU->Pool->Flatten->Dense->Softmax) and Trainer ====\n",
        "import math\n",
        "import random\n",
        "\n",
        "class TinyCNN:\n",
        "    def __init__(self, in_channels, conv_filters, kernel, pool, hidden, n_classes):\n",
        "        self.conv = Conv1D(in_channels, conv_filters, kernel)\n",
        "        self.relu = ReLU()\n",
        "        self.pool = MaxPool1D(pool)\n",
        "        self.flat = Flatten()\n",
        "        T_in = WIN\n",
        "        conv_T = T_in - kernel + 1\n",
        "        pool_T = conv_T // pool\n",
        "        flat_dim = pool_T * conv_filters\n",
        "        self.fc = Dense(flat_dim, hidden)\n",
        "        self.out = Dense(hidden, n_classes)\n",
        "\n",
        "    def forward(self, x_seq):\n",
        "        z = self.conv.forward(x_seq)\n",
        "        z = self.relu.forward(z)\n",
        "        z = self.pool.forward(z)\n",
        "        z = self.flat.forward(z)\n",
        "        z = self.fc.forward(z)\n",
        "        z = [max(v, -50) for v in z]  # mild clamp (원래 코드 그대로)\n",
        "        z = self.out.forward(z)       # logits\n",
        "        return z\n",
        "\n",
        "    def backward(self, dlogits, lr):\n",
        "        dz = self.out.backward(dlogits, lr)\n",
        "        dz = self.fc.backward(dz, lr)\n",
        "        dz = self.flat.backward(dz, lr)\n",
        "        dz = self.pool.backward(dz, lr)\n",
        "        dz = self.relu.backward(dz, lr)\n",
        "        dz = self.conv.backward(dz, lr)\n",
        "        return dz\n",
        "\n",
        "def iterate_minibatches(X, Y, batch_size):\n",
        "    idx = list(range(len(X)))\n",
        "    random.shuffle(idx)\n",
        "    for i in range(0, len(idx), batch_size):\n",
        "        b = idx[i:i+batch_size]\n",
        "        yield [X[j] for j in b], [Y[j] for j in b]\n",
        "\n",
        "def train_epoch(model, X, Y, lr, label_smoothing=0.05):\n",
        "    total_loss = 0.0\n",
        "    n = 0\n",
        "    correct = 0\n",
        "\n",
        "    idx = list(range(len(X)))\n",
        "    random.shuffle(idx)\n",
        "\n",
        "    seen = 0\n",
        "    for i in idx:\n",
        "        x_i, y_i = X[i], Y[i]\n",
        "        logits = model.forward(x_i)\n",
        "        probs  = softmax(logits)\n",
        "        loss, dlogits = cross_entropy_with_label_smoothing(probs, y_i, N_CLASSES, eps=label_smoothing)\n",
        "        total_loss += loss\n",
        "        n += 1\n",
        "        if probs.index(max(probs)) == y_i:\n",
        "            correct += 1\n",
        "        model.backward(dlogits, lr)\n",
        "\n",
        "        seen += 1\n",
        "        if seen % 512 == 0:\n",
        "            print(f\"    progress: {seen}/{len(X)} samples\")\n",
        "\n",
        "    acc = (correct/float(n)) if n>0 else 0.0\n",
        "    return total_loss/max(1,n), acc\n",
        "\n",
        "def evaluate(model, X, Y):\n",
        "    correct = 0\n",
        "    n = 0\n",
        "    K = N_CLASSES\n",
        "    cm = [[0 for _ in range(K)] for _ in range(K)]\n",
        "    for i in range(len(X)):\n",
        "        logits = model.forward(X[i])\n",
        "        probs = softmax(logits)\n",
        "        yhat = probs.index(max(probs))\n",
        "        cm[Y[i]][yhat] += 1\n",
        "        if yhat == Y[i]:\n",
        "            correct += 1\n",
        "        n += 1\n",
        "    acc = correct / float(n) if n>0 else 0.0\n",
        "    return acc, cm\n",
        "\n",
        "def print_confusion_matrix(cm):\n",
        "    K = len(cm)\n",
        "    print(\"Confusion Matrix (rows=True, cols=Pred):\")\n",
        "    for r in range(K):\n",
        "        print(\"y={:2d}: \".format(r), cm[r])\n"
      ],
      "metadata": {
        "id": "sQDgBzkPAZ-h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5-Fold 주체 CV 실행"
      ],
      "metadata": {
        "id": "f72C6uNeAYo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Cell 7: Run 5-fold subject-wise CV (EarlyStop + LR decay + F1 report) ====\n",
        "def copy_params(model):\n",
        "    import copy\n",
        "    def deep(x): return copy.deepcopy(x)\n",
        "    return {\n",
        "        'conv_W': deep(model.conv.W), 'conv_b': deep(model.conv.b),\n",
        "        'fc_W':   deep(model.fc.W),   'fc_b':   deep(model.fc.b),\n",
        "        'out_W':  deep(model.out.W),  'out_b':  deep(model.out.b),\n",
        "    }\n",
        "\n",
        "def load_params(model, p):\n",
        "    # in-place copy\n",
        "    for oc in range(len(model.conv.W)):\n",
        "        for ic in range(len(model.conv.W[0])):\n",
        "            for k in range(len(model.conv.W[0][0])):\n",
        "                model.conv.W[oc][ic][k] = p['conv_W'][oc][ic][k]\n",
        "        model.conv.b[oc] = p['conv_b'][oc]\n",
        "    for o in range(len(model.fc.W)):\n",
        "        for i in range(len(model.fc.W[0])):\n",
        "            model.fc.W[o][i] = p['fc_W'][o][i]\n",
        "        model.fc.b[o] = p['fc_b'][o]\n",
        "    for o in range(len(model.out.W)):\n",
        "        for i in range(len(model.out.W[0])):\n",
        "            model.out.W[o][i] = p['out_W'][o][i]\n",
        "        model.out.b[o] = p['out_b'][o]\n",
        "\n",
        "def run_cv(table):\n",
        "    MAX_EPOCHS = 5\n",
        "    PATIENCE   = 2\n",
        "    LR_DECAY   = 0.5\n",
        "\n",
        "    # 리포트용\n",
        "    from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
        "\n",
        "    fold_results = []\n",
        "    for fold_id, pair in enumerate(FOLDS, start=1):\n",
        "        print(\"\\n==============================\")\n",
        "        print(f\"Fold {fold_id}: Test subjects = {pair}\")\n",
        "        Xtr, Ytr, Xte, Yte = build_fold_data(table, pair, win=WIN, stride=STRIDE, maj_thresh=MAJ_THRESH)\n",
        "        print(f\"Train windows: {len(Xtr)} | Test windows: {len(Xte)}\")\n",
        "        if len(Xtr) == 0 or len(Xte) == 0:\n",
        "            print(\"[WARN] No data in this fold (maybe files missing). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        model = TinyCNN(IN_CHANNELS, CONV_FILTERS, KERNEL_SIZE, POOL_SIZE, HIDDEN_UNITS, N_CLASSES)\n",
        "        lr = LR\n",
        "        best_acc = -1.0\n",
        "        best_params = None\n",
        "        bad_epochs = 0\n",
        "\n",
        "        for ep in range(1, MAX_EPOCHS+1):\n",
        "            loss, tr_acc = train_epoch(model, Xtr, Ytr, lr, label_smoothing=LABEL_SMOOTHING)\n",
        "            te_acc, _ = evaluate(model, Xte, Yte)\n",
        "            print(f\"  Epoch {ep:02d} | lr={lr:.5f} | loss={loss:.4f} | train_acc={tr_acc*100:.2f}% | test_acc={te_acc*100:.2f}%\")\n",
        "\n",
        "            if te_acc > best_acc:\n",
        "                best_acc = te_acc\n",
        "                best_params = copy_params(model)\n",
        "                bad_epochs = 0\n",
        "            else:\n",
        "                bad_epochs += 1\n",
        "                # 향상 없으면 lr 감소\n",
        "                lr *= LR_DECAY\n",
        "\n",
        "            if bad_epochs >= PATIENCE:\n",
        "                print(f\"  Early stop at epoch {ep} (best_acc={best_acc*100:.2f}%)\")\n",
        "                break\n",
        "\n",
        "        # 베스트로 복구 후 평가/리포트\n",
        "        if best_params is not None:\n",
        "            load_params(model, best_params)\n",
        "\n",
        "        # 최종 예측 생성\n",
        "        y_pred = []\n",
        "        for w in Xte:\n",
        "            logits = model.forward(w)\n",
        "            probs = softmax(logits)\n",
        "            y_pred.append(int(probs.index(max(probs))))\n",
        "\n",
        "        # 정확도/혼동행렬/리포트\n",
        "        acc_final = accuracy_score(Yte, y_pred)\n",
        "        cm = confusion_matrix(Yte, y_pred, labels=list(range(N_CLASSES)))\n",
        "        fold_results.append(acc_final)\n",
        "        print(f\"[Fold {fold_id}] Best Test Accuracy: {acc_final*100:.2f}%\")\n",
        "        print_confusion_matrix(cm)  # 텍스트 혼동행렬\n",
        "\n",
        "        # === F1 리포트 추가 ===\n",
        "        class_names = globals().get(\"CLASS_NAMES\", [str(i) for i in range(N_CLASSES)])\n",
        "        macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
        "            Yte, y_pred, labels=list(range(N_CLASSES)), average='macro', zero_division=0\n",
        "        )\n",
        "        weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(\n",
        "            Yte, y_pred, labels=list(range(N_CLASSES)), average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        print(\"\\n=== Summary (Fold {} ) ===\".format(fold_id))\n",
        "        print(f\"Accuracy          : {acc_final*100:6.2f}%\")\n",
        "        print(f\"Macro Precision   : {macro_p*100:6.2f}%\")\n",
        "        print(f\"Macro Recall      : {macro_r*100:6.2f}%\")\n",
        "        print(f\"Macro F1          : {macro_f1*100:6.2f}%\")\n",
        "        print(f\"Weighted Precision: {weighted_p*100:6.2f}%\")\n",
        "        print(f\"Weighted Recall   : {weighted_r*100:6.2f}%\")\n",
        "        print(f\"Weighted F1       : {weighted_f1*100:6.2f}%\")\n",
        "\n",
        "        print(\"\\n=== Per-class (sklearn) ===\")\n",
        "        print(classification_report(\n",
        "            Yte, y_pred,\n",
        "            labels=list(range(N_CLASSES)),\n",
        "            target_names=class_names,\n",
        "            zero_division=0\n",
        "        ))\n",
        "\n",
        "    if fold_results:\n",
        "        avg = sum(fold_results)/len(fold_results)\n",
        "        print(\"\\n===== CV Summary =====\")\n",
        "        for i, a in enumerate(fold_results, start=1):\n",
        "            print(f\"Fold {i}: {a*100:.2f}%\")\n",
        "        print(f\"Mean: {avg*100:.2f}%\")\n",
        "    else:\n",
        "        print(\"[INFO] No folds computed.\")\n",
        "\n",
        "# Launch CV\n",
        "run_cv(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3yUfR0AX3C",
        "outputId": "87c7429d-393b-4fc3-d2ed-7390a835203a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Fold 1: Test subjects = (1, 2)\n",
            "Train windows: 4240 | Test windows: 1101\n",
            "    progress: 512/4240 samples\n",
            "    progress: 1024/4240 samples\n",
            "    progress: 1536/4240 samples\n",
            "    progress: 2048/4240 samples\n",
            "    progress: 2560/4240 samples\n",
            "    progress: 3072/4240 samples\n",
            "    progress: 3584/4240 samples\n",
            "    progress: 4096/4240 samples\n",
            "  Epoch 01 | lr=0.01000 | loss=1.0801 | train_acc=73.35% | test_acc=68.76%\n",
            "    progress: 512/4240 samples\n",
            "    progress: 1024/4240 samples\n",
            "    progress: 1536/4240 samples\n",
            "    progress: 2048/4240 samples\n",
            "    progress: 2560/4240 samples\n",
            "    progress: 3072/4240 samples\n",
            "    progress: 3584/4240 samples\n",
            "    progress: 4096/4240 samples\n",
            "  Epoch 02 | lr=0.01000 | loss=0.5574 | train_acc=95.90% | test_acc=83.02%\n",
            "    progress: 512/4240 samples\n",
            "    progress: 1024/4240 samples\n",
            "    progress: 1536/4240 samples\n",
            "    progress: 2048/4240 samples\n",
            "    progress: 2560/4240 samples\n",
            "    progress: 3072/4240 samples\n",
            "    progress: 3584/4240 samples\n",
            "    progress: 4096/4240 samples\n",
            "  Epoch 03 | lr=0.01000 | loss=0.4824 | train_acc=98.37% | test_acc=81.83%\n",
            "    progress: 512/4240 samples\n",
            "    progress: 1024/4240 samples\n",
            "    progress: 1536/4240 samples\n",
            "    progress: 2048/4240 samples\n",
            "    progress: 2560/4240 samples\n",
            "    progress: 3072/4240 samples\n",
            "    progress: 3584/4240 samples\n",
            "    progress: 4096/4240 samples\n",
            "  Epoch 04 | lr=0.00500 | loss=0.4399 | train_acc=99.60% | test_acc=81.47%\n",
            "  Early stop at epoch 4 (best_acc=83.02%)\n",
            "[Fold 1] Best Test Accuracy: 83.02%\n",
            "Confusion Matrix (rows=True, cols=Pred):\n",
            "y= 0:  [96  0  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 1:  [48 48  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 2:  [ 0  0 96  0  0  0  0  0  0  0  0  0]\n",
            "y= 3:  [ 0  0  0 93  3  0  0  0  0  0  0  0]\n",
            "y= 4:  [ 0  5  0  0 90  0  0  1  0  0  0  0]\n",
            "y= 5:  [14  0  0  0  0 78  0  5  0  0  0  0]\n",
            "y= 6:  [ 0  3  0  0  0  0 97  0  0  0  0  0]\n",
            "y= 7:  [ 8  0  0  0 11  1  0 85  0  0  0  0]\n",
            "y= 8:  [ 0  0  0  0  0  0  2  0 93  0  0  0]\n",
            "y= 9:  [ 0  0  0  0  0  0  7  0  0 85  4  0]\n",
            "y=10:  [ 0  0  0  2  4  0  5  1  0 38 38  8]\n",
            "y=11:  [ 0  0  0  0  3  1  0  3  3  7  0 15]\n",
            "\n",
            "=== Summary (Fold 1 ) ===\n",
            "Accuracy          :  83.02%\n",
            "Macro Precision   :  84.57%\n",
            "Macro Recall      :  80.99%\n",
            "Macro F1          :  80.67%\n",
            "Weighted Precision:  85.75%\n",
            "Weighted Recall   :  83.02%\n",
            "Weighted F1       :  82.26%\n",
            "\n",
            "=== Per-class (sklearn) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      1.00      0.73        96\n",
            "           1       0.86      0.50      0.63        96\n",
            "           2       1.00      1.00      1.00        96\n",
            "           3       0.98      0.97      0.97        96\n",
            "           4       0.81      0.94      0.87        96\n",
            "           5       0.97      0.80      0.88        97\n",
            "           6       0.87      0.97      0.92       100\n",
            "           7       0.89      0.81      0.85       105\n",
            "           8       0.97      0.98      0.97        95\n",
            "           9       0.65      0.89      0.75        96\n",
            "          10       0.90      0.40      0.55        96\n",
            "          11       0.65      0.47      0.55        32\n",
            "\n",
            "    accuracy                           0.83      1101\n",
            "   macro avg       0.85      0.81      0.81      1101\n",
            "weighted avg       0.86      0.83      0.82      1101\n",
            "\n",
            "\n",
            "==============================\n",
            "Fold 2: Test subjects = (3, 4)\n",
            "Train windows: 4241 | Test windows: 1100\n",
            "    progress: 512/4241 samples\n",
            "    progress: 1024/4241 samples\n",
            "    progress: 1536/4241 samples\n",
            "    progress: 2048/4241 samples\n",
            "    progress: 2560/4241 samples\n",
            "    progress: 3072/4241 samples\n",
            "    progress: 3584/4241 samples\n",
            "    progress: 4096/4241 samples\n",
            "  Epoch 01 | lr=0.01000 | loss=1.0450 | train_acc=73.33% | test_acc=81.55%\n",
            "    progress: 512/4241 samples\n",
            "    progress: 1024/4241 samples\n",
            "    progress: 1536/4241 samples\n",
            "    progress: 2048/4241 samples\n",
            "    progress: 2560/4241 samples\n",
            "    progress: 3072/4241 samples\n",
            "    progress: 3584/4241 samples\n",
            "    progress: 4096/4241 samples\n",
            "  Epoch 02 | lr=0.01000 | loss=0.6308 | train_acc=92.38% | test_acc=85.55%\n",
            "    progress: 512/4241 samples\n",
            "    progress: 1024/4241 samples\n",
            "    progress: 1536/4241 samples\n",
            "    progress: 2048/4241 samples\n",
            "    progress: 2560/4241 samples\n",
            "    progress: 3072/4241 samples\n",
            "    progress: 3584/4241 samples\n",
            "    progress: 4096/4241 samples\n",
            "  Epoch 03 | lr=0.01000 | loss=0.5520 | train_acc=95.40% | test_acc=86.73%\n",
            "    progress: 512/4241 samples\n",
            "    progress: 1024/4241 samples\n",
            "    progress: 1536/4241 samples\n",
            "    progress: 2048/4241 samples\n",
            "    progress: 2560/4241 samples\n",
            "    progress: 3072/4241 samples\n",
            "    progress: 3584/4241 samples\n",
            "    progress: 4096/4241 samples\n",
            "  Epoch 04 | lr=0.01000 | loss=0.5173 | train_acc=96.72% | test_acc=87.45%\n",
            "    progress: 512/4241 samples\n",
            "    progress: 1024/4241 samples\n",
            "    progress: 1536/4241 samples\n",
            "    progress: 2048/4241 samples\n",
            "    progress: 2560/4241 samples\n",
            "    progress: 3072/4241 samples\n",
            "    progress: 3584/4241 samples\n",
            "    progress: 4096/4241 samples\n",
            "  Epoch 05 | lr=0.01000 | loss=0.4954 | train_acc=97.43% | test_acc=84.36%\n",
            "[Fold 2] Best Test Accuracy: 87.45%\n",
            "Confusion Matrix (rows=True, cols=Pred):\n",
            "y= 0:  [96  0  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 1:  [ 0 48  0  0  2  0  0 46  0  0  0  0]\n",
            "y= 2:  [ 0  0 96  0  0  0  0  0  0  0  0  0]\n",
            "y= 3:  [ 0  0  0 96  0  0  0  0  0  0  0  0]\n",
            "y= 4:  [ 0  0  0  1 87  1  5  1  1  0  0  0]\n",
            "y= 5:  [ 0  0  0  0  0 96  0  5  0  0  0  0]\n",
            "y= 6:  [  0   0   0   0   1   0 101   0   0   0   0   0]\n",
            "y= 7:  [ 0  0  0  0  2  2  0 80 13  0  0  0]\n",
            "y= 8:  [ 0  0  0  0  0  0  0  0 96  0  0  0]\n",
            "y= 9:  [ 0  0  0  1  1  0  0  0  0 41 53  0]\n",
            "y=10:  [ 0  0  0  0  0  0  0  0  0  0 96  0]\n",
            "y=11:  [ 0  0  0  0  0  0  2  0  0  0  1 29]\n",
            "\n",
            "=== Summary (Fold 2 ) ===\n",
            "Accuracy          :  87.45%\n",
            "Macro Precision   :  91.16%\n",
            "Macro Recall      :  87.54%\n",
            "Macro F1          :  87.16%\n",
            "Weighted Precision:  90.65%\n",
            "Weighted Recall   :  87.45%\n",
            "Weighted F1       :  86.78%\n",
            "\n",
            "=== Per-class (sklearn) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        96\n",
            "           1       1.00      0.50      0.67        96\n",
            "           2       1.00      1.00      1.00        96\n",
            "           3       0.98      1.00      0.99        96\n",
            "           4       0.94      0.91      0.92        96\n",
            "           5       0.97      0.95      0.96       101\n",
            "           6       0.94      0.99      0.96       102\n",
            "           7       0.61      0.82      0.70        97\n",
            "           8       0.87      1.00      0.93        96\n",
            "           9       1.00      0.43      0.60        96\n",
            "          10       0.64      1.00      0.78        96\n",
            "          11       1.00      0.91      0.95        32\n",
            "\n",
            "    accuracy                           0.87      1100\n",
            "   macro avg       0.91      0.88      0.87      1100\n",
            "weighted avg       0.91      0.87      0.87      1100\n",
            "\n",
            "\n",
            "==============================\n",
            "Fold 3: Test subjects = (5, 6)\n",
            "Train windows: 4310 | Test windows: 1031\n",
            "    progress: 512/4310 samples\n",
            "    progress: 1024/4310 samples\n",
            "    progress: 1536/4310 samples\n",
            "    progress: 2048/4310 samples\n",
            "    progress: 2560/4310 samples\n",
            "    progress: 3072/4310 samples\n",
            "    progress: 3584/4310 samples\n",
            "    progress: 4096/4310 samples\n",
            "  Epoch 01 | lr=0.01000 | loss=1.0159 | train_acc=75.17% | test_acc=78.08%\n",
            "    progress: 512/4310 samples\n",
            "    progress: 1024/4310 samples\n",
            "    progress: 1536/4310 samples\n",
            "    progress: 2048/4310 samples\n",
            "    progress: 2560/4310 samples\n",
            "    progress: 3072/4310 samples\n",
            "    progress: 3584/4310 samples\n",
            "    progress: 4096/4310 samples\n",
            "  Epoch 02 | lr=0.01000 | loss=0.5985 | train_acc=94.06% | test_acc=79.24%\n",
            "    progress: 512/4310 samples\n",
            "    progress: 1024/4310 samples\n",
            "    progress: 1536/4310 samples\n",
            "    progress: 2048/4310 samples\n",
            "    progress: 2560/4310 samples\n",
            "    progress: 3072/4310 samples\n",
            "    progress: 3584/4310 samples\n",
            "    progress: 4096/4310 samples\n",
            "  Epoch 03 | lr=0.01000 | loss=0.5519 | train_acc=95.92% | test_acc=80.21%\n",
            "    progress: 512/4310 samples\n",
            "    progress: 1024/4310 samples\n",
            "    progress: 1536/4310 samples\n",
            "    progress: 2048/4310 samples\n",
            "    progress: 2560/4310 samples\n",
            "    progress: 3072/4310 samples\n",
            "    progress: 3584/4310 samples\n",
            "    progress: 4096/4310 samples\n",
            "  Epoch 04 | lr=0.01000 | loss=0.5240 | train_acc=96.47% | test_acc=81.18%\n",
            "    progress: 512/4310 samples\n",
            "    progress: 1024/4310 samples\n",
            "    progress: 1536/4310 samples\n",
            "    progress: 2048/4310 samples\n",
            "    progress: 2560/4310 samples\n",
            "    progress: 3072/4310 samples\n",
            "    progress: 3584/4310 samples\n",
            "    progress: 4096/4310 samples\n",
            "  Epoch 05 | lr=0.01000 | loss=0.5197 | train_acc=96.89% | test_acc=83.90%\n",
            "[Fold 3] Best Test Accuracy: 83.90%\n",
            "Confusion Matrix (rows=True, cols=Pred):\n",
            "y= 0:  [96  0  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 1:  [ 0 48  0  0 48  0  0  0  0  0  0  0]\n",
            "y= 2:  [ 0  0 96  0  0  0  0  0  0  0  0  0]\n",
            "y= 3:  [ 3  0  0 59 34  0  0  0  0  0  0  0]\n",
            "y= 4:  [ 1  0  0  0 90  3  1  0  0  0  0  1]\n",
            "y= 5:  [ 0  0  0  0  1 76  0  0  0  0  0  0]\n",
            "y= 6:  [ 0  5  0  0  1  0 71  0  0  0  0  0]\n",
            "y= 7:  [ 1  0  0  0  2  3  0 72  0  0  0  0]\n",
            "y= 8:  [ 0  0  0  0  0  0  0  0 96  0  0  0]\n",
            "y= 9:  [ 0  0  0  0  0  0  0  0  0 48 48  0]\n",
            "y=10:  [ 0  0  0  0  0  0  0  0  0  0 96  0]\n",
            "y=11:  [ 0  0  0  0  0  3  1  5  0  5  0 17]\n",
            "\n",
            "=== Summary (Fold 3 ) ===\n",
            "Accuracy          :  83.90%\n",
            "Macro Precision   :  89.05%\n",
            "Macro Recall      :  82.77%\n",
            "Macro F1          :  83.28%\n",
            "Weighted Precision:  88.47%\n",
            "Weighted Recall   :  83.90%\n",
            "Weighted F1       :  83.59%\n",
            "\n",
            "=== Per-class (sklearn) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97        96\n",
            "           1       0.91      0.50      0.64        96\n",
            "           2       1.00      1.00      1.00        96\n",
            "           3       1.00      0.61      0.76        96\n",
            "           4       0.51      0.94      0.66        96\n",
            "           5       0.89      0.99      0.94        77\n",
            "           6       0.97      0.92      0.95        77\n",
            "           7       0.94      0.92      0.93        78\n",
            "           8       1.00      1.00      1.00        96\n",
            "           9       0.91      0.50      0.64        96\n",
            "          10       0.67      1.00      0.80        96\n",
            "          11       0.94      0.55      0.69        31\n",
            "\n",
            "    accuracy                           0.84      1031\n",
            "   macro avg       0.89      0.83      0.83      1031\n",
            "weighted avg       0.88      0.84      0.84      1031\n",
            "\n",
            "\n",
            "==============================\n",
            "Fold 4: Test subjects = (7, 8)\n",
            "Train windows: 4289 | Test windows: 1052\n",
            "    progress: 512/4289 samples\n",
            "    progress: 1024/4289 samples\n",
            "    progress: 1536/4289 samples\n",
            "    progress: 2048/4289 samples\n",
            "    progress: 2560/4289 samples\n",
            "    progress: 3072/4289 samples\n",
            "    progress: 3584/4289 samples\n",
            "    progress: 4096/4289 samples\n",
            "  Epoch 01 | lr=0.01000 | loss=1.1227 | train_acc=70.34% | test_acc=71.20%\n",
            "    progress: 512/4289 samples\n",
            "    progress: 1024/4289 samples\n",
            "    progress: 1536/4289 samples\n",
            "    progress: 2048/4289 samples\n",
            "    progress: 2560/4289 samples\n",
            "    progress: 3072/4289 samples\n",
            "    progress: 3584/4289 samples\n",
            "    progress: 4096/4289 samples\n",
            "  Epoch 02 | lr=0.01000 | loss=0.6159 | train_acc=92.70% | test_acc=82.13%\n",
            "    progress: 512/4289 samples\n",
            "    progress: 1024/4289 samples\n",
            "    progress: 1536/4289 samples\n",
            "    progress: 2048/4289 samples\n",
            "    progress: 2560/4289 samples\n",
            "    progress: 3072/4289 samples\n",
            "    progress: 3584/4289 samples\n",
            "    progress: 4096/4289 samples\n",
            "  Epoch 03 | lr=0.01000 | loss=0.5426 | train_acc=95.62% | test_acc=74.71%\n",
            "    progress: 512/4289 samples\n",
            "    progress: 1024/4289 samples\n",
            "    progress: 1536/4289 samples\n",
            "    progress: 2048/4289 samples\n",
            "    progress: 2560/4289 samples\n",
            "    progress: 3072/4289 samples\n",
            "    progress: 3584/4289 samples\n",
            "    progress: 4096/4289 samples\n",
            "  Epoch 04 | lr=0.00500 | loss=0.4704 | train_acc=98.09% | test_acc=78.61%\n",
            "  Early stop at epoch 4 (best_acc=82.13%)\n",
            "[Fold 4] Best Test Accuracy: 82.13%\n",
            "Confusion Matrix (rows=True, cols=Pred):\n",
            "y= 0:  [96  0  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 1:  [ 0 48  0  0 48  0  0  0  0  0  0  0]\n",
            "y= 2:  [ 0  0 96  0  0  0  0  0  0  0  0  0]\n",
            "y= 3:  [ 0  0  0 96  0  0  0  0  0  0  0  0]\n",
            "y= 4:  [ 0  6  0  5 83  0  1  0  0  0  0  0]\n",
            "y= 5:  [ 0  0  0  0  0 81  0  0  0  0  0  0]\n",
            "y= 6:  [ 1 14  5  0  0  0 69  0  0  0  0  0]\n",
            "y= 7:  [ 0  0  0  0 33  0  0 51  0  0  0  0]\n",
            "y= 8:  [ 0  1  0  0  0  0  0 25 70  0  0  0]\n",
            "y= 9:  [ 0  0  0  0  0  4  5  0  0 55  3 29]\n",
            "y=10:  [ 0  0  0  1  0  0  1  0  0  1 93  0]\n",
            "y=11:  [ 0  0  0  0  0  2  0  0  1  0  2 26]\n",
            "\n",
            "=== Summary (Fold 4 ) ===\n",
            "Accuracy          :  82.13%\n",
            "Macro Precision   :  83.19%\n",
            "Macro Recall      :  82.21%\n",
            "Macro F1          :  81.05%\n",
            "Weighted Precision:  85.43%\n",
            "Weighted Recall   :  82.13%\n",
            "Weighted F1       :  82.29%\n",
            "\n",
            "=== Per-class (sklearn) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        96\n",
            "           1       0.70      0.50      0.58        96\n",
            "           2       0.95      1.00      0.97        96\n",
            "           3       0.94      1.00      0.97        96\n",
            "           4       0.51      0.87      0.64        95\n",
            "           5       0.93      1.00      0.96        81\n",
            "           6       0.91      0.78      0.84        89\n",
            "           7       0.67      0.61      0.64        84\n",
            "           8       0.99      0.73      0.84        96\n",
            "           9       0.98      0.57      0.72        96\n",
            "          10       0.95      0.97      0.96        96\n",
            "          11       0.47      0.84      0.60        31\n",
            "\n",
            "    accuracy                           0.82      1052\n",
            "   macro avg       0.83      0.82      0.81      1052\n",
            "weighted avg       0.85      0.82      0.82      1052\n",
            "\n",
            "\n",
            "==============================\n",
            "Fold 5: Test subjects = (9, 10)\n",
            "Train windows: 4284 | Test windows: 1057\n",
            "    progress: 512/4284 samples\n",
            "    progress: 1024/4284 samples\n",
            "    progress: 1536/4284 samples\n",
            "    progress: 2048/4284 samples\n",
            "    progress: 2560/4284 samples\n",
            "    progress: 3072/4284 samples\n",
            "    progress: 3584/4284 samples\n",
            "    progress: 4096/4284 samples\n",
            "  Epoch 01 | lr=0.01000 | loss=1.1416 | train_acc=70.96% | test_acc=65.09%\n",
            "    progress: 512/4284 samples\n",
            "    progress: 1024/4284 samples\n",
            "    progress: 1536/4284 samples\n",
            "    progress: 2048/4284 samples\n",
            "    progress: 2560/4284 samples\n",
            "    progress: 3072/4284 samples\n",
            "    progress: 3584/4284 samples\n",
            "    progress: 4096/4284 samples\n",
            "  Epoch 02 | lr=0.01000 | loss=0.6694 | train_acc=91.95% | test_acc=90.92%\n",
            "    progress: 512/4284 samples\n",
            "    progress: 1024/4284 samples\n",
            "    progress: 1536/4284 samples\n",
            "    progress: 2048/4284 samples\n",
            "    progress: 2560/4284 samples\n",
            "    progress: 3072/4284 samples\n",
            "    progress: 3584/4284 samples\n",
            "    progress: 4096/4284 samples\n",
            "  Epoch 03 | lr=0.01000 | loss=0.5939 | train_acc=94.63% | test_acc=88.84%\n",
            "    progress: 512/4284 samples\n",
            "    progress: 1024/4284 samples\n",
            "    progress: 1536/4284 samples\n",
            "    progress: 2048/4284 samples\n",
            "    progress: 2560/4284 samples\n",
            "    progress: 3072/4284 samples\n",
            "    progress: 3584/4284 samples\n",
            "    progress: 4096/4284 samples\n",
            "  Epoch 04 | lr=0.00500 | loss=0.5025 | train_acc=97.99% | test_acc=92.43%\n",
            "    progress: 512/4284 samples\n",
            "    progress: 1024/4284 samples\n",
            "    progress: 1536/4284 samples\n",
            "    progress: 2048/4284 samples\n",
            "    progress: 2560/4284 samples\n",
            "    progress: 3072/4284 samples\n",
            "    progress: 3584/4284 samples\n",
            "    progress: 4096/4284 samples\n",
            "  Epoch 05 | lr=0.00500 | loss=0.4847 | train_acc=98.39% | test_acc=94.13%\n",
            "[Fold 5] Best Test Accuracy: 94.13%\n",
            "Confusion Matrix (rows=True, cols=Pred):\n",
            "y= 0:  [96  0  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 1:  [ 0 96  0  0  0  0  0  0  0  0  0  0]\n",
            "y= 2:  [ 0  0 96  0  0  0  0  0  0  0  0  0]\n",
            "y= 3:  [ 0  0  0 74 22  0  0  0  0  0  0  0]\n",
            "y= 4:  [ 0  0  0  0 92  0  0  4  0  0  0  0]\n",
            "y= 5:  [ 0  0  0  0  0 81  0  1  0  0  0  0]\n",
            "y= 6:  [ 0 12  0  0  0  0 69  0  5  0  0  0]\n",
            "y= 7:  [ 0  0  0  0  0 16  0 74  0  0  0  0]\n",
            "y= 8:  [ 0  0  0  0  0  0  0  0 96  0  0  0]\n",
            "y= 9:  [ 0  0  0  0  0  0  0  0  0 96  0  0]\n",
            "y=10:  [ 0  0  0  0  0  0  0  0  0  2 94  0]\n",
            "y=11:  [ 0  0  0  0  0  0  0  0  0  0  0 31]\n",
            "\n",
            "=== Summary (Fold 5 ) ===\n",
            "Accuracy          :  94.13%\n",
            "Macro Precision   :  94.98%\n",
            "Macro Recall      :  94.34%\n",
            "Macro F1          :  94.27%\n",
            "Weighted Precision:  94.78%\n",
            "Weighted Recall   :  94.13%\n",
            "Weighted F1       :  94.06%\n",
            "\n",
            "=== Per-class (sklearn) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        96\n",
            "           1       0.89      1.00      0.94        96\n",
            "           2       1.00      1.00      1.00        96\n",
            "           3       1.00      0.77      0.87        96\n",
            "           4       0.81      0.96      0.88        96\n",
            "           5       0.84      0.99      0.91        82\n",
            "           6       1.00      0.80      0.89        86\n",
            "           7       0.94      0.82      0.88        90\n",
            "           8       0.95      1.00      0.97        96\n",
            "           9       0.98      1.00      0.99        96\n",
            "          10       1.00      0.98      0.99        96\n",
            "          11       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           0.94      1057\n",
            "   macro avg       0.95      0.94      0.94      1057\n",
            "weighted avg       0.95      0.94      0.94      1057\n",
            "\n",
            "\n",
            "===== CV Summary =====\n",
            "Fold 1: 83.02%\n",
            "Fold 2: 87.45%\n",
            "Fold 3: 83.90%\n",
            "Fold 4: 82.13%\n",
            "Fold 5: 94.13%\n",
            "Mean: 86.13%\n"
          ]
        }
      ]
    }
  ]
}